{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to another web container of words.</p> <p>Here I will collect some of my knowledge that might be useful for others.</p> <p>Enjoy!</p>"},{"location":"#articles","title":"Articles","text":"<p>{{ blog_content }}</p>"},{"location":"articles/2022-02-19-Github_pages_website_tutorial/","title":"BAAC - Blog as a Code","text":"","tags":["blog","mkdocs","github"]},{"location":"articles/2022-02-19-Github_pages_website_tutorial/#introduction","title":"Introduction","text":"<p>Many times I thought I would like a website where to share some of my knowledge, write some technical articles. Not sure if anyone would read it, but at least I knew what I wanted from it:</p> <ul> <li>as simple to manage as possible   I'm not a designer (although I like design) and don't want to loose my mind in building and managing a website.</li> <li>write like a dev   I would like to improve my coding skills, and write better documentation directly in my repos.   I thought \"Why couldn't I write articles in the same way as I write code? Maybe simply using Markdown?\"</li> <li>own the source code   Although there are many platforms for blogging, I usually dislike the idea of not owning the \"source code\" of my articles, i.e., each platform uses different styles/codes and it's difficult to download everything you write</li> </ul> <p>The solution I came up with is:</p> <ul> <li>use GitHub to store my site and use GitHub Pages to display it</li> <li>use MkDocs and MkDocs Material to write everything in Markdown and transform it into a nice looking website</li> <li>use GitHub Actions to automatize the deployment of changes and publishing of new articles</li> </ul> <p>Here is a simple description of how this website was created and how I covered the aforementioned needs.</p>","tags":["blog","mkdocs","github"]},{"location":"articles/2022-02-19-Github_pages_website_tutorial/#initial-website","title":"Initial Website","text":"<p>These are the steps I followed to have a working website with automatic updates when I write something.</p> <p>Create an empty repository named <code>{git username}.github.io</code>. For example, in my case it's <code>stawo.github.io</code>.</p> <p></p> <p>From the web interface, create the file <code>.gitignore</code>, just add a space in it (otherwise you cannot save it), and commit it. This step is useful to initiate the repo and avoid having to do it locally on the computer later on.</p> <p>(optional, but strongly suggested) Create conda env with <code>mkdocs</code> installed and activate it:</p> <pre><code>conda create -c conda-forge --name stawo.github.io python=3.10 mkdocs-material\nconda activate stawo.github.io\n</code></pre> <p>If you don't have/want <code>conda</code>, just run:</p> <pre><code>pip install mkdocs-material\n</code></pre> <p>Clone the repository on computer and access the root folder. In my case, I opened the terminal, went to my repositories folder, and ran:  </p> <pre><code>git clone https://github.com/stawo/stawo.github.io.git\ncd stawo.github.io.git\n</code></pre> <p>Initialize the website with MkDocs by executing</p> <pre><code>mkdocs new .\n</code></pre> <p>and test it by running</p> <pre><code>mkdocs serve\n</code></pre> <p>This should give the following website at the address http://127.0.0.1:8000/ </p> <p>Build the website by running</p> <pre><code>mkdocs build\n</code></pre> <p>This generates the folder <code>site/</code> with many files in it. This is the final website that we want to publish, but not in this way.</p> <p>Add <code>site/</code> to <code>.gitignore</code>, so that we can build locally with <code>mkdocs build</code> to test things but avoid having the generated files in git. We can test it by running <code>git status</code> and see that the generated files in the folder <code>site/</code> do not appear. You should see only <code>docs/</code> and <code>mkdocs.yml</code></p> <p></p> <p>Create the folder <code>.github/workflows</code> and add file <code>build_site.yml</code> with following code (from https://github.com/marketplace/actions/deploy-mkdocs):</p> <pre><code>name: Publish site via GitHub Pages\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    name: Deploy docs\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout main\n        uses: actions/checkout@v2\n\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n\n      - name: Install libraries\n      - run: pip install mkdocs-material\n\n      - name: Generate docs\n      - run: mkdocs gh-deploy --force\n</code></pre> <p>Commit changes. This will trigger the GitHub Actions. If all goes fine, the branch <code>gh-pages</code> will be created with the mkdocs build of our website. Check the progress of the pipeline on the repo website under <code>Actions</code>.</p> <p>To publish the generated website, go on the GitHub website of the repo, go to <code>Settings-&gt;Pages</code> and select the branch <code>gh-pages</code> as the source. The website will be visible at the address <code>https://{git username}.github.io/</code>. For example, in my case it's https://stawo.github.io/.</p> <p></p> <p>Note: it takes a little bit of time for GitHub to pick up changes, so don't worry if you get an error, just retry to refresh the page.</p>","tags":["blog","mkdocs","github"]},{"location":"articles/2022-02-19-Github_pages_website_tutorial/#resources","title":"Resources","text":"<ul> <li>https://squidfunk.github.io/mkdocs-material</li> <li>https://squidfunk.github.io/mkdocs-material/publishing-your-site/#github-pages</li> </ul>","tags":["blog","mkdocs","github"]},{"location":"articles/2022-02-19-Github_pages_website_tutorial/#power-up-blog","title":"Power-up: Blog!","text":"<p>Already with the previous set up you can publish things, but I'm lazy, and I would like that whenever I write an article (i.e., a Markdown file), this will automatically added and published without touching anything else.</p> <p>To do that, we can use the plugin Mkdocs Blogging Plugin.</p> <p>Install the plugin:</p> <pre><code>pip install mkdocs-blogging-plugin\n</code></pre> <p>To tell the plugin that everything in the folder <code>articles</code> should be considered an article and automatically publish it, modify <code>mkdocs.yml</code> and make it look something like this:  </p> <pre><code>site_name: My Docs\n\nsite_url: https://stawo.github.io/\n\nplugins:\n  - search\n  - blogging:\n    dirs:\n      - articles\n</code></pre> <p>Note: we added <code>- search</code> as we need to re-enable the search bar (see https://squidfunk.github.io/mkdocs-material/setup/setting-up-site-search/#built-in-search)</p> <p>We also have to modify <code>build_site.yml</code> like this:</p> <pre><code>name: Publish site via GitHub Pages\non:\n  push:\n    branches:\n      - main\n\njobs:\n  build:\n    name: Deploy docs\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout main\n        uses: actions/checkout@v2\n        with:\n          fetch-depth: 0\n\n      - name: Setup Python\n        uses: actions/setup-python@v2\n        with:\n          python-version: 3.x\n\n      - name: Install libraries\n      - run: pip install \\\n          mkdocs-material \\\n          mkdocs-blogging-plugin\n\n      - name: Generate docs\n      - run: mkdocs gh-deploy --force\n</code></pre> <p>And done! You now have an automated blog </p>","tags":["blog","mkdocs","github"]},{"location":"articles/2022-02-23-Pyodbc_and_complex_TSQL_stored_procedures/","title":"Complex TSQL stored procedures and PyODBC","text":"<p>Assume you have a database that you want to manage via a Python program, but for certain operations over your tables (e.g., data updates), you need to execute a complex stored procedure. With complex I mean a stored procedure that might contain multiple statements like <code>INSERT</code>, <code>UPDATE</code>, and <code>DELETE</code>, possibly using variables and temporary tables too.</p> <p>What I want:</p> <ul> <li>be able to call the stored procedure from my Python script;</li> <li>catch if any error happens during the execution of the stored procedure and details of it;</li> <li>capture some sort of log from the execution of the stored procedure (imagine if we could have something like <code>logger.info()</code> in the SQL code).</li> </ul> <p>I must say that I banged my head more than I would have liked to get all of that using PyODBC and stored procedure over a MS SQL Server. PyODBC seems pretty picky of what can happen in the stored procedure when calling it.</p> <p>Briefly, to make it work, the stored procedure:</p> <ul> <li>cannot contain <code>PRINT</code> and <code>RAISEERROR</code> statements;</li> <li>must declare <code>SET NOCOUNT ON</code> at the beginning of the procedure;</li> <li>can contain only 1 <code>SELECT</code> statement (if you use the <code>TRY...CATCH</code> statements, you can put 1 <code>SELECT</code> in each block).</li> </ul> <p>And here is the SQL template that I created:</p> <pre><code>CREATE PROCEDURE [stored procedure name]\n    -- INPUT PARAMETERS\n    @input1 type,\n    ...\n    @inputN type,\n    -- OUTPUT PARAMETERS - DO NOT MODIFY\n    @sp_exit_value int OUTPUT,\n    @sp_log nvarchar(max) OUTPUT,\n    @sp_error nvarchar(max) OUTPUT\nAS\nBEGIN TRY\n\n    -- MUST SET NOCOUNT ON\n    -- Without it, the call from python will fail\n    SET NOCOUNT ON;\n\n    declare @message nvarchar(max);\n\n    -- NCHAR(13)+NCHAR(10) represents a new line\n    -- https://stackoverflow.com/questions/53115490/how-to-correctly-insert-newline-in-nvarchar\n    set @message = concat(@message,NCHAR(13)+NCHAR(10),'Start');\n\n    ----------------------------------------------------------------\n\n    -- YOUR CODE HERE\n\n    ----------------------------------------------------------------\n\n    -- Output\n\n    set @message = concat(@message,NCHAR(13)+NCHAR(10),'End');\n\n    SELECT\n        @sp_exit_value = 0,\n        @sp_log = @message,\n        @sp_error = Null\n        ;\n\nEND TRY\nBEGIN CATCH  \n\n    SELECT\n        @sp_exit_value = -1,\n        @sp_log = @message,\n        @sp_error = concat(\n            'ERROR_NUMBER: ', ERROR_NUMBER(),\n            NCHAR(13)+NCHAR(10),'ERROR_SEVERITY: ', ERROR_SEVERITY(),\n            NCHAR(13)+NCHAR(10),'ERROR_STATE: ', ERROR_STATE(),\n            NCHAR(13)+NCHAR(10),'ERROR_PROCEDURE: ', ERROR_PROCEDURE(),\n            NCHAR(13)+NCHAR(10),'ERROR_LINE: ', ERROR_LINE(),\n            NCHAR(13)+NCHAR(10),'ERROR_MESSAGE: ', ERROR_MESSAGE()\n        )\n        ;\nEND CATCH;\n</code></pre> <p>You can modify the template above to fit your needs. In particulat, note the command:</p> <pre><code>set @message = concat(@message,NCHAR(13)+NCHAR(10),'YOUR TEXT');\n</code></pre> <p>That forms the logging functionality of the stored procedure.</p> <p>In your Python code, we will call the stored procedure using the following template:</p> <pre><code>import sqlalchemy\n\nsp_name = \"stored procedure name\"\nprefix = \"dbo\"\n\nparameters = [\n    input1 value,\n    ...,\n    inputN value,\n]\n\n# This part is needed as parameters needs to be escaped\n# based on their type to be properly passed in the SQL\n# command EXEC\nescaped_parameters = []\n    for parameter in parameters:\n        if isinstance(parameter, (int, float)):\n            escaped_parameters.append(str(parameter))\n        elif isinstance(parameter, bool):\n            escaped_parameters.append(\"1\" if parameter else \"0\")\n        else:\n            escaped_parameters.append(f\"'{str(parameter)}'\")\n\nsql_query = f\"\"\"\\\nDECLARE @exit_value int;\nDECLARE @log nvarchar(max);\nDECLARE @error nvarchar(max);\n        EXEC [{prefix}].[{sp_name}] {', '.join(escaped_parameters)}{',' if len(escaped_parameters)&gt;0 else ''} @sp_exit_value=@exit_value OUTPUT, @sp_log=@log OUTPUT, @sp_error=@error OUTPUT;\nSELECT @exit_value AS exit_value, @log AS log, @error AS error;\n\"\"\"\n\nengine = sqlalchemy.create_engine(\"mssql+pyodbc:/// CONNECTION STRING\")\n\nwith engine.begin() as connection:\n    sql_results = connection.execute(sql_query)\n\n    if sql_results.returns_rows:\n        # We retrieve the first row of the results (which should be the only row)\n        for row in sql_results:\n            results = {\n                \"exit_value\": row[0],\n                \"log\": row[1],\n                \"error\": row[2],\n            }\n            break\n    else:\n        ValueError(\"The stored procedure did not return any row, but it should!\")\n\nif results['exit_value'] &lt; 0:\n    message = f\"Failed to execute stored procedure [{sp_name}].\\nError:\\n{results['error']}\\n--------\\nLog:\\n{results['log']}\\n--------\"\n    raise ExecError(message)\n</code></pre> <p>Just in case you were thinking of it, do not use the Pandas function <code>read_sql()</code> to execute the stored procedure. This function, as the name implies (duh!), is designed to only read data, and does not commit any changes the stored procedure might perform.</p> <pre><code># DON'T DO THIS\npandas.read_sql(sql_query, engine)\n</code></pre> <p>Ok, that's all, have fun!</p>","tags":["sql","pyodbc","sqlalchemy","python","microsoft sql server"]},{"location":"articles/2022-02-23-Pyodbc_and_complex_TSQL_stored_procedures/#resources","title":"Resources","text":"<ul> <li>https://www.sqlservertutorial.net/sql-server-stored-procedures/stored-procedure-output-parameters/</li> <li>https://docs.microsoft.com/en-us/sql/t-sql/language-elements/try-catch-transact-sql?view=sql-server-ver15</li> </ul>","tags":["sql","pyodbc","sqlalchemy","python","microsoft sql server"]},{"location":"articles/2022-04-28-Github_workflow_publish_repo_to_Databricks/","title":"Github workflow to publish a repo to a Databricks workspace","text":"<p>Here is a quick code snippet of a Github workflow that publishes (or updates, if it already exists) a repository to a Databricks workspace.</p> <p>I assume you already configured your repository provider in the Databricks workspace: https://docs.databricks.com/repos/index.html</p> <pre><code># ------------------------------------------------------------\n# GITHUB WORKFLOW TO PUBLISH/UPDATE A GIT REPO IN DATABRICKS WORKSPACE\n# \n# In this workflow we publish a new repo or update an existing one\n# in a given Databricks workspace.\n# The workflow also allows to set 2 environments:\n# - production\n# - development\n# The two environments can point to two different DB workspaces\n# The workflow is triggered by commits and, depending on the branch,\n# it uses one of the two environments.\n# More specifically, the branch name defined in the var\n# `PROD_BRANCH_NAME` dictates which branch is considered as production.\n# \n# We assume the following secrets are defined:\n# - DATABRICKS_HOST_PROD : Production workspace url\n# - DATABRICKS_TOKEN_PROD : Token to access the production workspace\n# - DATABRICKS_HOST_DEV : Development workspace url\n# - DATABRICKS_TOKEN_DEV : Token to access the development workspace\n# ------------------------------------------------------------\n\nname: Databricks\n\n# NOTE: a succesfull PR (i.e. that is approved and merged), generates\n# a commit on the target branch, so we don't need to specify `pull_request`\non:\n  push:\n    # branches:\n    #   - main\n\nenv:\n  # Name of the branch that represents the production code\n  # Usually it's `main` or `master`\n  PROD_BRANCH_NAME: main\n  # Path in the Databricks workspace where to store the repo\n  DATABRICKS_REPO_PATH: \"/Repos/folder/name\"\n  # Repo url\n  DATABRICKS_REPO_URL: https://github.com/repo_url\n  # See https://docs.databricks.com/dev-tools/cli/repos-cli.html#create-a-repo\n  DATABRICKS_REPO_PROVIDER: gitHub\n\njobs:\n  databricks:\n\n    runs-on: ubuntu-latest\n\n    steps:\n\n      # ---------------------------------------\n      # SET ENV VARS FOR DIFFERENT ENVIRONMENTS\n      # We select the values for `host` and `token` depending on the branch.\n      # If we are in `main` (or the value set in `PROD_BRANCH_NAME`), then we\n      # retrieve the production values, otherwise we take the development ones.\n      # This is achieved using the two conditional steps below.\n      # As an example, in the condition\n      # `${{ github.ref_name == env.PROD_BRANCH_NAME }}`\n      # `github.ref_name` might have the `development` if we performed a commit in that branch.\n      # https://docs.github.com/en/actions/learn-github-actions/contexts#github-context\n\n      - name: Sets env vars for Production\n        if: ${{ github.ref_name == env.PROD_BRANCH_NAME }}\n        run: |\n          echo \"DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_PROD }}\" &gt;&gt; $GITHUB_ENV\n          echo \"DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_PROD }}\" &gt;&gt; $GITHUB_ENV\n\n      - name: Sets env vars for Development\n        if: ${{ github.ref_name != env.PROD_BRANCH_NAME }}\n        run: |\n          echo \"DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_DEV }}\" &gt;&gt; $GITHUB_ENV\n          echo \"DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_DEV }}\" &gt;&gt; $GITHUB_ENV\n\n      # ---------------------------------------\n      # INSTALL DATABRICKS-CLI AND CONFIGURE IT\n\n      - name: Install databricks-cli\n        run: python -m pip install databricks-cli\n        shell: bash\n\n      - name: Set `.databrickscfg`\n        run: | \n          cat &gt; ~/.databrickscfg &lt;&lt;EOF \n          [DEFAULT] \n          host = ${{ env.DATABRICKS_HOST }}\n          token = ${{ env.DATABRICKS_TOKEN }}\n          EOF\n\n      # ---------------------------------------\n      # TEST DATABRICKS-CLI\n\n      - name: List all repos\n        run: databricks repos list\n\n      # ---------------------------------------\n      # PUBLISH SELECTED REPO\n      #\n      # Code breakdown:\n      # - ERR=0\n      #   We initialize the var `ERR` to 0. This var represents if the\n      #   following command executes successfully (0) or not (1)\n      # - `databricks repos get --path ${{ env.DATABRICKS_REPO_PATH }}`\n      #   Tries to get details about repo with path `DATABRICKS_REPO_PATH`.\n      #   If it does not exist, it fails with exist status -1.\n      # - ... || ERR=1\n      #   this part is executed if the previous command fails, in which\n      #   case we assign 1 to ERR\n      #   https://stackoverflow.com/questions/65754507/bash-pipe-get-the-exit-status-of-previous-process-in-pipeline\n      # - `if [...]; then ...; else ...; fi`\n      #   if-then-else statement, https://www.geeksforgeeks.org/bash-scripting-if-statement/\n      # - `ERR -eq 0`\n      #   Checks if `ERR` is equal to 0\n      # - `echo \"::set-output name=repo_exists::1\"`\n      #   Add to the outputs of the step the output `repo_exists` with value 1\n      - name: Check for repo existence\n        id: check_repo_existence\n        run: |\n          ERR=0\n          databricks repos get --path ${{ env.DATABRICKS_REPO_PATH }} || ERR=1\n          if [ $ERR -eq 0 ]; then echo \"Repo exists\"; else echo \"Repo does not exist\"; fi\n          if [ $ERR -eq 0 ]; then echo \"::set-output name=repo_exists::1\"; else echo \"::set-output name=repo_exists::0\"; fi\n\n      # Check if the step `check_repo_existence` output `` is 0,\n      # meaning that the repo `DATABRICKS_REPO_PATH` does not exist\n      # https://docs.github.com/en/actions/learn-github-actions/contexts#steps-context\n      # In that case, we create the repository and switch to the branch\n      # that triggered this workflow.\n      # We use `${{ github.ref_name }}` to get the name of the branch\n      # https://docs.github.com/en/actions/learn-github-actions/contexts#github-context\n      - name: Repo does not exist, create it\n        if: steps.check_repo_existence.outputs.repo_exists == 0\n        run: |\n          echo \"Repo does not exist!\"\n          databricks repos create --url ${{ env.DATABRICKS_REPO_URL }} --provider ${{ env.DATABRICKS_REPO_PROVIDER }} --path ${{ env.DATABRICKS_REPO_PATH }}\n          databricks repos update --path ${{ env.DATABRICKS_REPO_PATH }} --branch ${{ github.ref_name }}\n\n      # If the repo already exists, we update it.\n      # We use `${{ github.ref_name }}` to get the name of the branch\n      # https://docs.github.com/en/actions/learn-github-actions/contexts#github-context\n      - name: Repo exists, update it\n        if: steps.check_repo_existence.outputs.repo_exists == 1\n        run: |\n          echo \"Repo exists!\"\n          databricks repos update --path ${{ env.DATABRICKS_REPO_PATH }} --branch ${{ github.ref_name }}\n</code></pre>","tags":["github","databricks","ci-cd"]}]}