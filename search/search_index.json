{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Welcome to another web container of words. Here I will collect some of my knowledge that might be useful for others. Enjoy! Articles {{ blog_content }}","title":"Home"},{"location":"#home","text":"Welcome to another web container of words. Here I will collect some of my knowledge that might be useful for others. Enjoy!","title":"Home"},{"location":"#articles","text":"{{ blog_content }}","title":"Articles"},{"location":"articles/2022-02-19-Github_pages_website_tutorial/","tags":["blog","mkdocs"],"text":"Introduction Many times I thought I would like a website where to share some of my knowledge, write some technical articles. Not sure if anyone would read it, but at least I knew what I wanted from it: as simple to manage as possible I'm not a designer (although I like design) and don't want to loose my mind in building and managing a website. write like a dev I would like to improve my coding skills, and write better documentation directly in my repos. I thought \"Why couldn't I write articles in the same way as I write code? Maybe simply using Markdown?\" own the source code Although there are many platforms for blogging, I usually dislike the idea of not owning the \"source code\" of my articles, i.e., each platform uses different styles/codes and it's difficult to download everything you write The solution I came up with is: use GitHub to store my site and use GitHub Pages to display it use MkDocs and MkDocs Material to write everything in Markdown and transform it into a nice looking website use GitHub Actions to automatize the deployment of changes and publishing of new articles Here is a simple description of how this website was created and how I covered the aforementioned needs. Initial Website These are the steps I followed to have a working website with automatic updates when I write something. Create an empty repository named {git username}.github.io . For example, in my case it's stawo.github.io . From the web interface, create the file .gitignore , just add a space in it (otherwise you cannot save it), and commit it. This step is useful to initiate the repo and avoid having to do it locally on the computer later on. (optional, but strongly suggested) Create conda env with mkdocs installed and activate it: conda create --name stawo.github.io python=3.10 mkdocs-material conda activate stawo.github.io If you don't have/want conda , just run: pip install mkdocs-material Clone the repository on computer and access the root folder. In my case, I opened the terminal, went to my repositories folder, and ran: git clone https://github.com/stawo/stawo.github.io.git cd stawo.github.io.git Initialize the website with MkDocs by executing mkdocs new . and test it by running mkdocs serve This should give the following website at the address http://127.0.0.1:8000/ Build the website by running mkdocs build This generates the folder site/ with many files in it. This is the final website that we want to publish, but not in this way. Add site/ to .gitignore , so that we can build locally with mkdocs build to test things but avoid having the generated files in git. We can test it by running git status and see that the generated files in the folder site/ do not appear. You should see only docs/ and mkdocs.yml Create the folder .github/workflows and add file build_site.yml with following code ( from https://github.com/marketplace/actions/deploy-mkdocs ): name: Publish site via GitHub Pages on: push: branches: - main jobs: build: name: Deploy docs runs-on: ubuntu-latest steps: - name: Checkout main uses: actions/checkout@v2 - name: Setup Python uses: actions/setup-python@v2 with: python-version: 3.x - name: Install libraries - run: pip install mkdocs-material - name: Generate docs - run: mkdocs gh-deploy --force Commit changes. This will trigger the GitHub Actions. If all goes fine, the branch gh-pages will be created with the mkdocs build of our website. Check the progress of the pipeline on the repo website under Actions . To publish the generated website, go on the GitHub website of the repo, go to Settings->Pages and select the branch gh-pages as the source. The website will be visible at the address https://{git username}.github.io/ . For example, in my case it's https://stawo.github.io/ . Note : it takes a little bit of time for GitHub to pick up changes, so don't worry if you get an error, just retry to refresh the page. Resources https://squidfunk.github.io/mkdocs-material https://squidfunk.github.io/mkdocs-material/publishing-your-site/#github-pages Power-up: Blog! Already with the previous set up you can publish things, but I'm lazy, and I would like that whenever I write an article (i.e., a Markdown file), this will automatically added and published without touching anything else. To do that, we can use the plugin Mkdocs Blogging Plugin . Install the plugin: pip install mkdocs-blogging-plugin To tell the plugin that everything in the folder articles should be considered an article and automatically publish it, modify mkdocs.yml and make it look something like this: site_name: My Docs site_url: https://stawo.github.io/ plugins: - search - blogging: dirs: - articles Note : we added - search as we need to re-enable the search bar (see https://squidfunk.github.io/mkdocs-material/setup/setting-up-site-search/#built-in-search ) We also have to modify build_site.yml like this: name: Publish site via GitHub Pages on: push: branches: - main jobs: build: name: Deploy docs runs-on: ubuntu-latest steps: - name: Checkout main uses: actions/checkout@v2 with: fetch-depth: 0 - name: Setup Python uses: actions/setup-python@v2 with: python-version: 3.x - name: Install libraries - run: pip install \\ mkdocs-material \\ mkdocs-blogging-plugin - name: Generate docs - run: mkdocs gh-deploy --force And done! You now have an automated blog","title":"My lazy Dev dream for publishing!"},{"location":"articles/2022-02-19-Github_pages_website_tutorial/#introduction","text":"Many times I thought I would like a website where to share some of my knowledge, write some technical articles. Not sure if anyone would read it, but at least I knew what I wanted from it: as simple to manage as possible I'm not a designer (although I like design) and don't want to loose my mind in building and managing a website. write like a dev I would like to improve my coding skills, and write better documentation directly in my repos. I thought \"Why couldn't I write articles in the same way as I write code? Maybe simply using Markdown?\" own the source code Although there are many platforms for blogging, I usually dislike the idea of not owning the \"source code\" of my articles, i.e., each platform uses different styles/codes and it's difficult to download everything you write The solution I came up with is: use GitHub to store my site and use GitHub Pages to display it use MkDocs and MkDocs Material to write everything in Markdown and transform it into a nice looking website use GitHub Actions to automatize the deployment of changes and publishing of new articles Here is a simple description of how this website was created and how I covered the aforementioned needs.","title":"Introduction"},{"location":"articles/2022-02-19-Github_pages_website_tutorial/#initial-website","text":"These are the steps I followed to have a working website with automatic updates when I write something. Create an empty repository named {git username}.github.io . For example, in my case it's stawo.github.io . From the web interface, create the file .gitignore , just add a space in it (otherwise you cannot save it), and commit it. This step is useful to initiate the repo and avoid having to do it locally on the computer later on. (optional, but strongly suggested) Create conda env with mkdocs installed and activate it: conda create --name stawo.github.io python=3.10 mkdocs-material conda activate stawo.github.io If you don't have/want conda , just run: pip install mkdocs-material Clone the repository on computer and access the root folder. In my case, I opened the terminal, went to my repositories folder, and ran: git clone https://github.com/stawo/stawo.github.io.git cd stawo.github.io.git Initialize the website with MkDocs by executing mkdocs new . and test it by running mkdocs serve This should give the following website at the address http://127.0.0.1:8000/ Build the website by running mkdocs build This generates the folder site/ with many files in it. This is the final website that we want to publish, but not in this way. Add site/ to .gitignore , so that we can build locally with mkdocs build to test things but avoid having the generated files in git. We can test it by running git status and see that the generated files in the folder site/ do not appear. You should see only docs/ and mkdocs.yml Create the folder .github/workflows and add file build_site.yml with following code ( from https://github.com/marketplace/actions/deploy-mkdocs ): name: Publish site via GitHub Pages on: push: branches: - main jobs: build: name: Deploy docs runs-on: ubuntu-latest steps: - name: Checkout main uses: actions/checkout@v2 - name: Setup Python uses: actions/setup-python@v2 with: python-version: 3.x - name: Install libraries - run: pip install mkdocs-material - name: Generate docs - run: mkdocs gh-deploy --force Commit changes. This will trigger the GitHub Actions. If all goes fine, the branch gh-pages will be created with the mkdocs build of our website. Check the progress of the pipeline on the repo website under Actions . To publish the generated website, go on the GitHub website of the repo, go to Settings->Pages and select the branch gh-pages as the source. The website will be visible at the address https://{git username}.github.io/ . For example, in my case it's https://stawo.github.io/ . Note : it takes a little bit of time for GitHub to pick up changes, so don't worry if you get an error, just retry to refresh the page.","title":"Initial Website"},{"location":"articles/2022-02-19-Github_pages_website_tutorial/#resources","text":"https://squidfunk.github.io/mkdocs-material https://squidfunk.github.io/mkdocs-material/publishing-your-site/#github-pages","title":"Resources"},{"location":"articles/2022-02-19-Github_pages_website_tutorial/#power-up-blog","text":"Already with the previous set up you can publish things, but I'm lazy, and I would like that whenever I write an article (i.e., a Markdown file), this will automatically added and published without touching anything else. To do that, we can use the plugin Mkdocs Blogging Plugin . Install the plugin: pip install mkdocs-blogging-plugin To tell the plugin that everything in the folder articles should be considered an article and automatically publish it, modify mkdocs.yml and make it look something like this: site_name: My Docs site_url: https://stawo.github.io/ plugins: - search - blogging: dirs: - articles Note : we added - search as we need to re-enable the search bar (see https://squidfunk.github.io/mkdocs-material/setup/setting-up-site-search/#built-in-search ) We also have to modify build_site.yml like this: name: Publish site via GitHub Pages on: push: branches: - main jobs: build: name: Deploy docs runs-on: ubuntu-latest steps: - name: Checkout main uses: actions/checkout@v2 with: fetch-depth: 0 - name: Setup Python uses: actions/setup-python@v2 with: python-version: 3.x - name: Install libraries - run: pip install \\ mkdocs-material \\ mkdocs-blogging-plugin - name: Generate docs - run: mkdocs gh-deploy --force And done! You now have an automated blog","title":"Power-up: Blog!"},{"location":"articles/2022-02-23-Pyodbc_and_complex_TSQL_stored_procedures/","tags":["sql","pyodbc","sqlalchemy","python","microsoft sql server"],"text":"Assume you have a database that you want to manage via a Python program, but for certain operations over your tables (e.g., data updates), you need to execute a complex stored procedure. With complex I mean a stored procedure that might contain multiple statements like INSERT , UPDATE , and DELETE , possibly using variables and temporary tables too. What I want: be able to call the stored procedure from my Python script; catch if any error happens during the execution of the stored procedure and details of it; capture some sort of log from the execution of the stored procedure (imagine if we could have something like logger.info() in the SQL code). I must say that I banged my head more than I would have liked to get all of that using PyODBC and stored procedure over a MS SQL Server. PyODBC seems pretty picky of what can happen in the stored procedure when calling it. Briefly, to make it work, the stored procedure: cannot contain PRINT and RAISEERROR statements; must declare SET NOCOUNT ON at the beginning of the procedure; can contain only 1 SELECT statement (if you use the TRY...CATCH statements, you can put 1 SELECT in each block). And here is the SQL template that I created: CREATE PROCEDURE [stored procedure name] -- INPUT PARAMETERS @input1 type, ... @inputN type, -- OUTPUT PARAMETERS - DO NOT MODIFY @sp_exit_value int OUTPUT, @sp_log nvarchar(max) OUTPUT, @sp_error nvarchar(max) OUTPUT AS BEGIN TRY -- MUST SET NOCOUNT ON -- Without it, the call from python will fail SET NOCOUNT ON; declare @message nvarchar(max); -- NCHAR(13)+NCHAR(10) represents a new line -- https://stackoverflow.com/questions/53115490/how-to-correctly-insert-newline-in-nvarchar set @message = concat(@message,NCHAR(13)+NCHAR(10),'Start'); ---------------------------------------------------------------- -- YOUR CODE HERE ---------------------------------------------------------------- -- Output set @message = concat(@message,NCHAR(13)+NCHAR(10),'End'); SELECT @sp_exit_value = 0, @sp_log = @message, @sp_error = Null ; END TRY BEGIN CATCH SELECT @sp_exit_value = -1, @sp_log = @message, @sp_error = concat( 'ERROR_NUMBER: ', ERROR_NUMBER(), NCHAR(13)+NCHAR(10),'ERROR_SEVERITY: ', ERROR_SEVERITY(), NCHAR(13)+NCHAR(10),'ERROR_STATE: ', ERROR_STATE(), NCHAR(13)+NCHAR(10),'ERROR_PROCEDURE: ', ERROR_PROCEDURE(), NCHAR(13)+NCHAR(10),'ERROR_LINE: ', ERROR_LINE(), NCHAR(13)+NCHAR(10),'ERROR_MESSAGE: ', ERROR_MESSAGE() ) ; END CATCH; You can modify the template above to fit your needs. In particulat, note the command: set @message = concat(@message,NCHAR(13)+NCHAR(10),'YOUR TEXT'); That forms the logging functionality of the stored procedure. In your Python code, we will call the stored procedure using the following template: import sqlalchemy sp_name = \"stored procedure name\" prefix = \"dbo\" parameters = [ input1 value, ..., inputN value, ] # This part is needed as parameters needs to be escaped # based on their type to be properly passed in the SQL # command EXEC escaped_parameters = [] for parameter in parameters: if isinstance(parameter, (int, float)): escaped_parameters.append(str(parameter)) elif isinstance(parameter, bool): escaped_parameters.append(\"1\" if parameter else \"0\") else: escaped_parameters.append(f\"'{str(parameter)}'\") sql_query = f\"\"\"\\ DECLARE @exit_value int; DECLARE @log nvarchar(max); DECLARE @error nvarchar(max); EXEC [{prefix}].[{sp_name}] {', '.join(escaped_parameters)}{',' if len(escaped_parameters)>0 else ''} @sp_exit_value=@exit_value OUTPUT, @sp_log=@log OUTPUT, @sp_error=@error OUTPUT; SELECT @exit_value AS exit_value, @log AS log, @error AS error; \"\"\" engine = sqlalchemy.create_engine(\"mssql+pyodbc:/// CONNECTION STRING\") with engine.begin() as connection: sql_results = connection.execute(sql_query) if sql_results.returns_rows: # We retrieve the first row of the results (which should be the only row) for row in sql_results: results = { \"exit_value\": row[0], \"log\": row[1], \"error\": row[2], } break else: ValueError(\"The stored procedure did not return any row, but it should!\") if results['exit_value'] < 0: message = f\"Failed to execute stored procedure [{sp_name}].\\nError:\\n{results['error']}\\n--------\\nLog:\\n{results['log']}\\n--------\" raise ExecError(message) Just in case you were thinking of it, do not use the Pandas function read_sql() to execute the stored procedure. This function, as the name implies (duh!), is designed to only read data, and does not commit any changes the stored procedure might perform. # DON'T DO THIS pandas.read_sql(sql_query, engine) Ok, that's all, have fun! Resources https://www.sqlservertutorial.net/sql-server-stored-procedures/stored-procedure-output-parameters/ https://docs.microsoft.com/en-us/sql/t-sql/language-elements/try-catch-transact-sql?view=sql-server-ver15","title":"Complex TSQL stored procedures and PyODBC"},{"location":"articles/2022-02-23-Pyodbc_and_complex_TSQL_stored_procedures/#resources","text":"https://www.sqlservertutorial.net/sql-server-stored-procedures/stored-procedure-output-parameters/ https://docs.microsoft.com/en-us/sql/t-sql/language-elements/try-catch-transact-sql?view=sql-server-ver15","title":"Resources"},{"location":"articles/2022-04-28-Github_workflow_publish_repo_to_Databricks/","tags":["github","databricks","ci-cd"],"text":"Here is a quick code snippet of a Github workflow that publishes (or updates, if it already exists) a repository to a Databricks workspace. I assume you already configured your repository provider in the Databricks workspace: https://docs.databricks.com/repos/index.html # ------------------------------------------------------------ # GITHUB WORKFLOW TO PUBLISH/UPDATE A GIT REPO IN DATABRICKS WORKSPACE # # In this workflow we publish a new repo or update an existing one # in a given Databricks workspace. # The workflow also allows to set 2 environments: # - production # - development # The two environments can point to two different DB workspaces # The workflow is triggered by commits and, depending on the branch, # it uses one of the two environments. # More specifically, the branch name defined in the var # `PROD_BRANCH_NAME` dictates which branch is considered as production. # # We assume the following secrets are defined: # - DATABRICKS_HOST_PROD : Production workspace url # - DATABRICKS_TOKEN_PROD : Token to access the production workspace # - DATABRICKS_HOST_DEV : Development workspace url # - DATABRICKS_TOKEN_DEV : Token to access the development workspace # ------------------------------------------------------------ name: Databricks # NOTE: a succesfull PR (i.e. that is approved and merged), generates # a commit on the target branch, so we don't need to specify `pull_request` on: push: # branches: # - main env: # Name of the branch that represents the production code # Usually it's `main` or `master` PROD_BRANCH_NAME: main # Path in the Databricks workspace where to store the repo DATABRICKS_REPO_PATH: \"/Repos/folder/name\" # Repo url DATABRICKS_REPO_URL: https://github.com/repo_url # See https://docs.databricks.com/dev-tools/cli/repos-cli.html#create-a-repo DATABRICKS_REPO_PROVIDER: gitHub jobs: databricks: runs-on: ubuntu-latest steps: # --------------------------------------- # SET ENV VARS FOR DIFFERENT ENVIRONMENTS # We select the values for `host` and `token` depending on the branch. # If we are in `main` (or the value set in `PROD_BRANCH_NAME`), then we # retrieve the production values, otherwise we take the development ones. # This is achieved using the two conditional steps below. # As an example, in the condition # `${{ github.ref_name == env.PROD_BRANCH_NAME }}` # `github.ref_name` might have the `development` if we performed a commit in that branch. # https://docs.github.com/en/actions/learn-github-actions/contexts#github-context - name: Sets env vars for Production if: ${{ github.ref_name == env.PROD_BRANCH_NAME }} run: | echo \"DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_PROD }}\" >> $GITHUB_ENV echo \"DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_PROD }}\" >> $GITHUB_ENV - name: Sets env vars for Development if: ${{ github.ref_name != env.PROD_BRANCH_NAME }} run: | echo \"DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_DEV }}\" >> $GITHUB_ENV echo \"DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_DEV }}\" >> $GITHUB_ENV # --------------------------------------- # INSTALL DATABRICKS-CLI AND CONFIGURE IT - name: Install databricks-cli run: python -m pip install databricks-cli shell: bash - name: Set `.databrickscfg` run: | cat > ~/.databrickscfg <<EOF [DEFAULT] host = ${{ env.DATABRICKS_HOST }} token = ${{ env.DATABRICKS_TOKEN }} EOF # --------------------------------------- # TEST DATABRICKS-CLI - name: List all repos run: databricks repos list # --------------------------------------- # PUBLISH SELECTED REPO # # Code breakdown: # - ERR=0 # We initialize the var `ERR` to 0. This var represents if the # following command executes successfully (0) or not (1) # - `databricks repos get --path ${{ env.DATABRICKS_REPO_PATH }}` # Tries to get details about repo with path `DATABRICKS_REPO_PATH`. # If it does not exist, it fails with exist status -1. # - ... || ERR=1 # this part is executed if the previous command fails, in which # case we assign 1 to ERR # https://stackoverflow.com/questions/65754507/bash-pipe-get-the-exit-status-of-previous-process-in-pipeline # - `if [...]; then ...; else ...; fi` # if-then-else statement, https://www.geeksforgeeks.org/bash-scripting-if-statement/ # - `ERR -eq 0` # Checks if `ERR` is equal to 0 # - `echo \"::set-output name=repo_exists::1\"` # Add to the outputs of the step the output `repo_exists` with value 1 - name: Check for repo existence id: check_repo_existence run: | ERR=0 databricks repos get --path ${{ env.DATABRICKS_REPO_PATH }} || ERR=1 if [ $ERR -eq 0 ]; then echo \"Repo exists\"; else echo \"Repo does not exist\"; fi if [ $ERR -eq 0 ]; then echo \"::set-output name=repo_exists::1\"; else echo \"::set-output name=repo_exists::0\"; fi # Check if the step `check_repo_existence` output `` is 0, # meaning that the repo `DATABRICKS_REPO_PATH` does not exist # https://docs.github.com/en/actions/learn-github-actions/contexts#steps-context # In that case, we create the repository and switch to the branch # that triggered this workflow. # We use `${{ github.ref_name }}` to get the name of the branch # https://docs.github.com/en/actions/learn-github-actions/contexts#github-context - name: Repo does not exist, create it if: steps.check_repo_existence.outputs.repo_exists == 0 run: | echo \"Repo does not exist!\" databricks repos create --url ${{ env.DATABRICKS_REPO_URL }} --provider ${{ env.DATABRICKS_REPO_PROVIDER }} --path ${{ env.DATABRICKS_REPO_PATH }} databricks repos update --path ${{ env.DATABRICKS_REPO_PATH }} --branch ${{ github.ref_name }} # If the repo already exists, we update it. # We use `${{ github.ref_name }}` to get the name of the branch # https://docs.github.com/en/actions/learn-github-actions/contexts#github-context - name: Repo exists, update it if: steps.check_repo_existence.outputs.repo_exists == 1 run: | echo \"Repo exists!\" databricks repos update --path ${{ env.DATABRICKS_REPO_PATH }} --branch ${{ github.ref_name }}","title":"Github workflow to publish a repo to a Databricks workspace"}]}